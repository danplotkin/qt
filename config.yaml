# configs for training transformer
training:
  learning_rate: 1e-4
  batch_size: 32
  epochs: 10
  weight_decay: 0.01
  output_dir: "./experiments"
  early_stopping: true
  early_stopping_patience: 5
  early_stopping_min_delta: 0.001
  early_stopping_mode: "min"
  restore_best_model: true
  logging_dir: "./logs"
  # s3_bucket: "your-bucket-name"
  # s3_prefix: "your/prefix/"

# qt configs
transformer:
  tgt_vocab_size: 50257
  d_model: 2048
  num_heads: 16
  num_layers: 14
  d_ff: 8192
  max_seq_length: 2048
  dropout: 0.1